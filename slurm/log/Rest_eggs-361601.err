Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 5000
Job stats:
job             count    min threads    max threads
------------  -------  -------------  -------------
all                 1              1              1
plot_summary        1              1              1
read_depth          1              2              2
total               3              1              2

Select jobs to execute...

[Wed Oct 11 09:29:46 2023]
Job 1001:  --- Running Rscript to plot the genome-wide distribution of coverage --- 
Reason: Missing output files: depth/stats/depth_statistics.tsv


    Rscript scripts/read_depth.R list/depth.list depth/stats/depth_statistics.tsv 2> log/depth_statistics.log 
    
Submitted job 1001 with external jobid 'Submitted batch job 361602'.
[Wed Oct 11 09:30:56 2023]
Error in rule read_depth:
    jobid: 1001
    input: list/depth.list
    output: depth/stats/depth_statistics.tsv
    log: log/depth_statistics.log (check log file(s) for error details)
    shell:
        
    Rscript scripts/read_depth.R list/depth.list depth/stats/depth_statistics.tsv 2> log/depth_statistics.log 
    
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)
    cluster_jobid: Submitted batch job 361602

Error executing rule read_depth on cluster (jobid: 1001, external: Submitted batch job 361602, jobscript: /gpfs/gpfs1/scratch/c7701178/mach2/DAPHNIA/Daphnia_RestEggs_4lakes_smk_slurm/.snakemake/tmp.3mzlshqq/snakejob.read_depth.1001.sh). For error details see the cluster log and the log files of the involved rule(s).
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-10-11T092943.746156.snakemake.log
